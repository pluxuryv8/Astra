from __future__ import annotations

import re
from dataclasses import dataclass
from typing import Any

"""
Lightweight local adaptation inspired by MetaGPT software workflow:
- tmp/metagpt/examples/build_customized_multi_agents.py
- tmp/metagpt/examples/use_off_the_shelf_agent.py

Implements a minimal PRD -> Code -> Review -> Test pipeline without external deps.
"""

_DEV_TASK_TOKENS = (
    "dev_task",
    "напиши модуль",
    "реализ",
    "feature",
    "фича",
    "код",
    "module",
    "тест",
    "refactor",
    "интегр",
)


def _normalized(value: str) -> str:
    return re.sub(r"\s+", " ", (value or "").strip().lower().replace("ё", "е"))


def _history_user_tail(history: list[dict[str, Any]] | None, limit: int = 5) -> list[str]:
    if not isinstance(history, list):
        return []
    rows: list[str] = []
    for item in history[-10:]:
        if not isinstance(item, dict):
            continue
        if str(item.get("role") or "").lower() != "user":
            continue
        content = item.get("content")
        if isinstance(content, str) and content.strip():
            rows.append(content.strip())
    return rows[-limit:]


def is_dev_task(
    requirement: str,
    *,
    tone_analysis: dict[str, Any] | None = None,
    history: list[dict[str, Any]] | None = None,
) -> bool:
    text = _normalized(requirement)
    if not text:
        return False

    token_hits = sum(1 for token in _DEV_TASK_TOKENS if token in text)
    words = [part for part in text.split(" ") if part]
    signals = tone_analysis.get("signals") if isinstance(tone_analysis, dict) else {}
    technical = int(signals.get("technical_density", 0)) if isinstance(signals, dict) else 0
    workflow = bool(tone_analysis.get("workflow")) if isinstance(tone_analysis, dict) else False
    task_complex = bool(tone_analysis.get("task_complex")) if isinstance(tone_analysis, dict) else False

    score = 0
    score += 3 if token_hits >= 1 else 0
    score += 1 if token_hits >= 2 else 0
    score += 1 if any(token in text for token in ("api", "python", "js", "sql", "class", "function")) else 0
    score += 1 if technical >= 1 else 0
    score += 1 if workflow else 0
    score += 1 if task_complex else 0
    score += 1 if len(words) >= 7 else 0
    if history and len(_history_user_tail(history, limit=6)) >= 3:
        score += 1
    return score >= 3


def _slugify(text: str, default: str = "feature_module") -> str:
    raw = re.sub(r"[^a-z0-9_]+", "_", _normalized(text))
    raw = re.sub(r"_+", "_", raw).strip("_")
    return raw[:48] or default


@dataclass(slots=True)
class DevArtifact:
    prd: str
    code: str
    review: str
    tests: str


def _build_prd(requirement: str) -> str:
    concise = requirement.strip()
    return (
        "PRD:\n"
        f"- Goal: {concise}\n"
        "- Scope: minimal vertical slice with clear input/output contract.\n"
        "- Constraints: preserve existing architecture, avoid new dependencies.\n"
        "- Acceptance: unit tests for happy path + edge cases."
    )


def _build_code(requirement: str) -> str:
    name = _slugify(requirement)
    return (
        "```python\n"
        f"def {name}(payload: dict) -> dict:\n"
        "    \"\"\"Generated by MetaGPT-style dev pipeline.\"\"\"\n"
        "    if not isinstance(payload, dict):\n"
        "        raise TypeError('payload must be dict')\n"
        "    result = {\n"
        "        'ok': True,\n"
        "        'input_keys': sorted(payload.keys()),\n"
        "        'summary': 'handled by generated module',\n"
        "    }\n"
        "    return result\n"
        "```\n"
    )


def _build_review(code: str) -> str:
    return (
        "Review:\n"
        "- Code keeps deterministic output.\n"
        "- Type validation exists for input payload.\n"
        "- Follow-up: connect function to actual domain logic in target module.\n"
        f"- Generated code size: {len(code)} chars."
    )


def _build_tests(requirement: str, function_name: str) -> str:
    return (
        "```python\n"
        "import pytest\n\n"
        f"from module import {function_name}\n\n"
        "def test_generated_ok_path():\n"
        f"    payload = {{'requirement': {requirement!r}}}\n"
        f"    result = {function_name}(payload)\n"
        "    assert result['ok'] is True\n"
        "    assert 'requirement' in result['input_keys']\n\n"
        "def test_generated_type_error():\n"
        "    with pytest.raises(TypeError):\n"
        f"        {function_name}('bad')\n"
        "```\n"
    )


def run(
    requirement: str,
    history: list[dict[str, Any]] | None = None,
    *,
    tone_analysis: dict[str, Any] | None = None,
) -> dict[str, Any]:
    history = history if isinstance(history, list) else []
    tone_analysis = tone_analysis if isinstance(tone_analysis, dict) else {}

    dev_task = is_dev_task(requirement, tone_analysis=tone_analysis, history=history)
    if not dev_task:
        return {
            "mode": "single",
            "dev_task": False,
            "executed": False,
            "prd": "",
            "code": "",
            "review": "",
            "tests": "",
            "generated_code": "",
            "summary": "MetaGPT dev pipeline not engaged.",
        }

    prd = _build_prd(requirement)
    code = _build_code(requirement)
    function_name = _slugify(requirement)
    review = _build_review(code)
    tests = _build_tests(requirement, function_name)

    artifact = DevArtifact(prd=prd, code=code, review=review, tests=tests)
    summary = (
        "MetaGPT dev pipeline executed: PRD -> Code -> Review -> Test; "
        f"function={function_name}."
    )
    return {
        "mode": "dev",
        "dev_task": True,
        "executed": True,
        "prd": artifact.prd,
        "code": artifact.code,
        "review": artifact.review,
        "tests": artifact.tests,
        "generated_code": artifact.code,
        "summary": summary,
    }


__all__ = ["DevArtifact", "is_dev_task", "run"]
